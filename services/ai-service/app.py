from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import io
import torch
import torchvision.transforms as transforms
from PIL import Image
import timm

app = FastAPI(title="Alzheimer Diagnosis AI Service")

# ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ Backend Core ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------------------------------------------------
# üß† 1. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏î Weights (state_dict)
# ---------------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = "model/efficientnetb0_alzheimer.pt"

try:
    # 1.1 ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á EfficientNetB0 ‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÜ ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô (num_classes=4 ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô)
    model = timm.create_model("efficientnet_b0", pretrained=False, num_classes=4)
    
    # 1.2 ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .pt ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Dictionary
    checkpoint = torch.load(model_path, map_location=device)
    
    # 1.3 ‡πÄ‡∏≠‡∏≤ Weights (state_dict) ‡πÉ‡∏™‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model.load_state_dict(checkpoint["model_state_dict"])
    
    model.to(device)
    model.eval() # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
    print("‚úÖ Model loaded successfully!")
    
except Exception as e:
    print(f"‚ùå Error loading model: {e}")
    model = None

# ---------------------------------------------------------
# üñºÔ∏è 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Image Transform ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏õ‡πä‡∏∞‡πÜ
# ---------------------------------------------------------
transform = transforms.Compose([
    transforms.Resize((128, 128)), # ‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏ä‡πâ 128
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # ‡∏Ñ‡πà‡∏≤ Mean/Std ‡∏ï‡∏≤‡∏° Notebook
])

# ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏•‡∏≤‡∏™‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ class_names ‡πÉ‡∏ô Notebook
CLASSES = ['Mild Demented', 'Moderate Demented', 'Non Demented', 'Very Mild Demented']

@app.get("/")
def read_root():
    return {"status": "AI Service is running", "device": str(device)}

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    if model is None:
        return {"error": "Model not loaded properly. Check server logs."}

    try:
        # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏µ‡πÄ‡∏õ‡πá‡∏ô RGB
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Tensor ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏¥‡∏ï‡∏¥ Batch
        img_tensor = transform(image).unsqueeze(0).to(device)
        
        # ---------------------------------------------------------
        # ü§ñ 3. ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
        # ---------------------------------------------------------
        with torch.no_grad():
            outputs = model(img_tensor)
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏î‡πâ‡∏ß‡∏¢ Softmax
            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
            
        # ‡∏´‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
        predicted_idx = torch.argmax(probabilities).item()
        predicted_class = CLASSES[predicted_idx]
        
        # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™ (‡∏Ñ‡∏π‡∏ì 100 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô %)
        prob_dict = {
            "mild": round(probabilities[0].item() * 100, 2),
            "moderate": round(probabilities[1].item() * 100, 2),
            "non": round(probabilities[2].item() * 100, 2),
            "very_mild": round(probabilities[3].item() * 100, 2)
        }

        return {
            "prediction": predicted_class,
            "probabilities": prob_dict,
            "filename": file.filename
        }

    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=5000)